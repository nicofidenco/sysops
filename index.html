<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AWS SysOps Quiz</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
    <style>
        body {
            font-family: 'Inter', sans-serif;
        }
        .quiz-container {
            max-width: 800px;
            width: 95%;
        }
        .answer-btn {
            transition: all 0.2s ease-in-out;
        }
        .answer-btn:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.1);
        }
        .correct {
            background-color: #10B981 !important; /* Tailwind green-500 */
            color: white !important;
            border-color: #059669 !important;
        }
        .incorrect {
            background-color: #EF4444 !important; /* Tailwind red-500 */
            color: white !important;
            border-color: #DC2626 !important;
        }
        .explanation {
            border-left: 4px solid #3B82F6; /* Tailwind blue-500 */
        }
    </style>
</head>
<body class="bg-gray-100 flex items-center justify-center min-h-screen py-8">

    <div id="quiz-container" class="quiz-container bg-white p-6 sm:p-8 rounded-2xl shadow-lg">
        <div id="quiz-header" class="mb-6">
            <h1 class="text-2xl sm:text-3xl font-bold text-gray-800 text-center">AWS SysOps Administrator Quiz</h1>
            <div id="progress-info" class="flex justify-between items-center mt-4 text-gray-600">
                <span id="question-counter"></span>
                <span id="score"></span>
            </div>
        </div>

        <div id="question-area">
            <p id="question-text" class="text-lg text-gray-700 mb-6 leading-relaxed"></p>
            <div id="answer-buttons" class="grid grid-cols-1 gap-4">
                <!-- Answer buttons will be generated here -->
            </div>
        </div>

        <div id="feedback-area" class="mt-6 hidden">
            <div id="explanation" class="explanation bg-blue-50 p-4 rounded-lg">
                <h3 class="font-bold text-lg mb-2 text-gray-800">Explanation</h3>
                <p id="explanation-text" class="text-gray-700"></p>
            </div>
        </div>

        <div id="navigation-area" class="mt-8 flex justify-end">
            <button id="next-btn" class="bg-blue-600 text-white font-semibold py-2 px-6 rounded-lg shadow-md hover:bg-blue-700 focus:outline-none focus:ring-2 focus:ring-blue-500 focus:ring-opacity-50 transition hidden">Next Question</button>
        </div>

        <div id="results-area" class="hidden text-center">
            <h2 class="text-2xl font-bold text-gray-800 mb-4">Quiz Complete!</h2>
            <p id="final-score" class="text-xl text-gray-700 mb-6"></p>
            <button id="restart-btn" class="bg-green-600 text-white font-semibold py-3 px-8 rounded-lg shadow-md hover:bg-green-700 focus:outline-none focus:ring-2 focus:ring-green-500 focus:ring-opacity-50 transition">Restart Quiz</button>
        </div>
    </div>

    <script>
        const questions = [
            {
                question: `A company hosts a Windows-based file server on EC2 instances across multiple Availability Zones. Application servers are unable to access files simultaneously. Which solution allows simultaneous file access in the MOST operationally efficient way?`,
                answers: [
                    { text: `Create an Amazon EFS Multi-AZ file system.`, correct: false, explanation: `Amazon EFS is designed for Linux-based workloads and uses the NFS protocol. It&apos;s not the native or most efficient solution for a Windows environment.` },
                    { text: `Create an Amazon FSx for Windows File Server Multi-AZ file system.`, correct: true, explanation: `Correct. Amazon FSx for Windows File Server is a fully managed service that provides shared file storage built on Windows Server, natively supporting the SMB protocol and Multi-AZ deployments.` },
                    { text: `Create an EBS volume with Multi-Attach enabled.`, correct: false, explanation: `EBS Multi-Attach allows an EBS volume to be attached to multiple instances, but only within the same Availability Zone, which does not meet the requirement.` },
                    { text: `Create two FSx for Windows file systems with DFS replication.`, correct: false, explanation: `While this would work, it is not the most operationally efficient solution. A single Multi-AZ FSx file system handles replication and failover automatically, reducing management overhead.` }
                ]
            },
            {
                question: `A company needs to automate daily incremental backups for any EBS volume tagged with &apos;Lifecycle: Production&apos;. A key requirement is to prevent users from deleting these production snapshots. What should a SysOps administrator do?`,
                answers: [
                    { text: `Use Amazon Data Lifecycle Manager to create daily snapshots.`, correct: false, explanation: `Amazon DLM can automate snapshot creation but lacks a feature like Vault Lock to prevent users with appropriate permissions from deleting the snapshots.` },
                    { text: `Use an SCP to deny snapshot deletion and an EventBridge rule to create snapshots.`, correct: false, explanation: `This solution is overly complex. A blanket SCP denial could interfere with legitimate operations, and AWS Backup is a more integrated tool for this.` },
                    { text: `Use AWS Backup with a tag-based policy and Vault Lock.`, correct: true, explanation: `Correct. AWS Backup is a centralized service that can automate tag-based backups and its &apos;Backup Vault Lock&apos; feature provides WORM protection, which prevents deletion.` },
                    { text: `Create a daily AMI of every production EC2 instance using DLM.`, correct: false, explanation: `The requirement is to back up EBS volumes, not entire EC2 instances. Creating an AMI is unnecessary and backs up more data than required.` }
                ]
            },
            {
                question: `An application on hundreds of EC2 instances across three AZs needs to call a third-party API that requires a static list of IP addresses for their allow list. Which solution meets this requirement?`,
                answers: [
                    { text: `Add a NAT gateway in the public subnet of each AZ.`, correct: true, explanation: `Correct. This is the classic architecture. A NAT Gateway in each AZ provides a static, public IP for all outbound traffic from private subnets in that AZ, resulting in a small, fixed list of IPs.` },
                    { text: `Allocate one Elastic IP address and associate it with all instances in each AZ.`, correct: false, explanation: `An Elastic IP address can only be associated with one EC2 instance at a time.` },
                    { text: `Place the instances behind a Network Load Balancer.`, correct: false, explanation: `Load balancers are designed for managing inbound traffic to your instances, not for routing outbound traffic from them.` },
                    { text: `Assign an Elastic IP address to each of the hundreds of instances.`, correct: false, explanation: `This is not operationally efficient, would be costly, and would result in a very long list of IP addresses, defeating the purpose of a simple allow list.` }
                ]
            },
            {
                question: `A SysOps administrator is hosting a static web app on an S3 bucket. A strict company policy dictates that all S3 buckets must remain private. How can the website be served to users?`,
                answers: [
                    { text: `Create a CloudFront distribution with an Origin Access Identity (OAI).`, correct: true, explanation: `Correct. This is the standard and most secure method. CloudFront acts as the public entry point, and an OAI is a special CloudFront user that can be granted permission to access the private S3 bucket.` },
                    { text: `Configure static website hosting in S3 and use a Route 53 CNAME.`, correct: false, explanation: `Configuring static website hosting on an S3 bucket requires the bucket and its objects to be made public, which violates the company policy.` },
                    { text: `Use an Application Load Balancer to forward traffic to the S3 bucket.`, correct: false, explanation: `While an ALB can route traffic, it is not the primary or most direct service for serving content from S3 while keeping the bucket private. CloudFront with OAI is the purpose-built solution.` },
                    { text: `Use AWS Global Accelerator to forward traffic to the S3 bucket.`, correct: false, explanation: `Global Accelerator is for improving global application availability and performance, not the primary tool for serving content from a private S3 bucket.` }
                ]
            },
            {
                question: `An application running on an EC2 instance needs to read, write, and delete messages from an SQS queue. Which solution is the MOST secure?`,
                answers: [
                    { text: `Embed an IAM user&apos;s credentials in the application&apos;s configuration.`, correct: false, explanation: `This is a significant security risk. If the instance is compromised, the attacker gains access to long-lived keys. IAM roles are the recommended alternative.` },
                    { text: `Use an IAM role with sqs:* permissions.`, correct: false, explanation: `While using an IAM role is correct, this option violates the principle of least privilege by using a wildcard (sqs:*), granting far more permissions than needed.` },
                    { text: `Export an IAM user&apos;s access keys as environment variables on the instance.`, correct: false, explanation: `This is also a security risk involving long-lived credentials. IAM roles avoid storing static keys on the instance.` },
                    { text: `Use an IAM role with specific SQS permissions (SendMessage, ReceiveMessage, DeleteMessage).`, correct: true, explanation: `Correct. This follows two key best practices: using an IAM Role for temporary, managed credentials, and adhering to the Principle of Least Privilege by granting only the specific permissions required.` }
                ]
            },
            {
                question: `A CloudFront distribution with an ALB origin isn&apos;t caching. Monitoring shows requests are still served by the ALB. Which of these is a possible cause?`,
                answers: [
                    { text: `CloudFront does not have the ALB configured as the origin access identity.`, correct: false, explanation: `Origin Access Identity (OAI) is used to restrict access to S3 bucket origins, not ALB origins.` },
                    { text: `The DNS is still pointing to the ALB instead of the CloudFront distribution.`, correct: true, explanation: `Correct. If the public DNS record still points directly to the ALB&apos;s DNS name, users will bypass CloudFront entirely. The DNS record must point to the CloudFront distribution&apos;s domain name.` },
                    { text: `The ALB security group is not permitting inbound traffic from CloudFront.`, correct: false, explanation: `If the ALB security group blocked traffic from CloudFront, users would receive errors (e.g., 502 Bad Gateway), not just see traffic served from the origin.` },
                    { text: `The target groups associated with the ALB are configured for sticky sessions.`, correct: false, explanation: `Sticky sessions on the ALB ensure that a user is consistently routed to the same backend EC2 instance but would not prevent CloudFront from caching content.` }
                ]
            },
            {
                question: `An RDS for PostgreSQL DB cluster needs a new, separate cluster from data less than 24 hours old. Which solution has the LEAST operational overhead?`,
                answers: [
                    { text: `Restore the most recent automated snapshot to a new RDS DB cluster.`, correct: true, explanation: `Correct. Restoring from the most recent automated snapshot is a simple, built-in RDS feature that can be done with a few clicks or a single API call, representing very low operational overhead.` },
                    { text: `Back up the database to S3 using native tools, then restore.`, correct: false, explanation: `Using native database tools involves many manual steps (backup, manage file, restore) and is significantly more operational overhead than using built-in RDS features.` },
                    { text: `Create a new RDS DB cluster and use AWS DMS to migrate data.`, correct: false, explanation: `AWS DMS is a powerful service for migrations but is overkill for simply cloning an existing RDS cluster and involves more setup (replication instances, tasks) than restoring a snapshot.` },
                    { text: `Use the pg_dump utility to export and pg_restore to import data.`, correct: false, explanation: `This is a manual process with high operational overhead compared to using the managed features of RDS.` }
                ]
            },
            {
                question: `A federated user&apos;s CloudFormation stack creation for an S3 bucket fails. The user has s3:CreateBucket permission. What is another likely cause?`,
                answers: [
                    { text: `The user&apos;s IAM policy does not allow the cloudformation:CreateStack action.`, correct: true, explanation: `Correct. To initiate the stack creation process, the user themselves must have the cloudformation:CreateStack permission. Without it, the request to create the stack will be denied immediately.` },
                    { text: `The user&apos;s IAM policy does not allow the cloudformation:CreateStackSet action.`, correct: false, explanation: `CreateStackSet is for deploying stacks across multiple accounts and regions. The scenario describes deploying a single stack, which uses the CreateStack action.` },
                    { text: `The user&apos;s IAM policy explicitly denies the s3:ListBucket action.`, correct: false, explanation: `s3:ListBucket is for listing contents of an existing bucket and is not required for the initial creation of the bucket itself.` },
                    { text: `The user&apos;s IAM policy explicitly denies the s3:PutObject action.`, correct: false, explanation: `s3:PutObject is for adding objects to an existing bucket and is not required for the initial creation of the bucket itself.` }
                ]
            },
            {
                question: `A financial app stores sensitive data in S3. Data must be encrypted at rest. The company doesn&apos;t want to manage keys but needs an audit trail of key usage. Which solution meets these requirements?`,
                answers: [
                    { text: `Use client-side encryption with client-provided keys.`, correct: false, explanation: `This option involves the company managing their own encryption keys, which violates the requirement.` },
                    { text: `Use server-side encryption with S3 managed encryption keys (SSE-S3).`, correct: false, explanation: `SSE-S3 is simple, but it does not provide a detailed CloudTrail audit log for the usage of the data keys, which is a key requirement.` },
                    { text: `Use server-side encryption with customer-provided encryption keys (SSE-C).`, correct: false, explanation: `This option involves the company providing and managing their own encryption keys, which violates the requirement.` },
                    { text: `Use server-side encryption with AWS KMS managed encryption keys (SSE-KMS).`, correct: true, explanation: `Correct. SSE-KMS meets both requirements. AWS manages the keys, and every use of the key is logged in AWS CloudTrail, providing the required audit trail.` }
                ]
            },
            {
                question: `A company uses AWS Organizations and needs to automate provisioning the same set of resources from the management account to multiple member accounts. Which solution will meet this requirement?`,
                answers: [
                    { text: `Create a CloudFormation change set.`, correct: false, explanation: `A change set is a preview of the changes a template will make to a single stack. It does not deploy anything across multiple accounts.` },
                    { text: `Create a CloudFormation nested stack.`, correct: false, explanation: `A nested stack is a way to reuse common template components within a single parent stack, not for deploying across accounts.` },
                    { text: `Create an AWS Serverless Application Model (AWS SAM) template.`, correct: false, explanation: `AWS SAM is an extension of CloudFormation for serverless applications and doesn&apos;t inherently provide multi-account deployment capabilities.` },
                    { text: `Create a CloudFormation StackSet.`, correct: true, explanation: `Correct. AWS CloudFormation StackSets are designed for this exact purpose, allowing you to create, update, or delete stacks across multiple accounts and regions with a single operation.` }
                ]
            },
            {
                question: `A SysOps administrator has created a custom AMI in the eu-west-2 Region. They need to use this same AMI to launch EC2 instances in us-east-1 and us-east-2. What must be done?`,
                answers: [
                    { text: `Copy the AMI to the additional Regions.`, correct: true, explanation: `Correct. AMIs are a regional resource. To use an AMI in another Region, you must explicitly copy it to the target Region. This creates a new, independent AMI in the destination.` },
                    { text: `Make the AMI public in the Community AMIs section.`, correct: false, explanation: `Making an AMI public would allow other accounts to use it, but it would still only be available within the Region where it was created.` },
                    { text: `Share the AMI to the additional Regions.`, correct: false, explanation: `Sharing an AMI allows other AWS accounts to use your private AMI, but this sharing is confined to the Region where the AMI exists. You cannot &apos;share&apos; an AMI to another Region.` },
                    { text: `Copy the AMI to a new S3 bucket and assign permissions.`, correct: false, explanation: `This is not the correct procedure. While an AMI&apos;s snapshot is stored in S3, you must use the &apos;Copy AMI&apos; action to make it available in another region.` }
                ]
            },
            {
                question: `A website on a single EC2 instance in a public subnet is unreachable. The security group allows inbound HTTP, and a new NACL also allows inbound HTTP. What is the cause?`,
                answers: [
                    { text: `The new network ACL is missing an outbound rule for ephemeral port return traffic.`, correct: true, explanation: `Correct. Network ACLs are stateless. You must define rules for both inbound and outbound traffic. The response traffic from the server to the user uses a random ephemeral port, so an outbound rule is required to allow this return traffic.` },
                    { text: `The security group is missing an outbound rule for HTTP.`, correct: false, explanation: `Security Groups are stateful. If you allow inbound traffic on a port, the corresponding return traffic is automatically allowed, regardless of outbound rules.` },
                    { text: `The Elastic IP address assigned to the EC2 instance has changed.`, correct: false, explanation: `Elastic IP addresses are static by definition and do not change unless you explicitly disassociate or release them.` },
                    { text: `An additional network ACL is denying traffic.`, correct: false, explanation: `A subnet can only have one NACL associated with it at a time. Applying a new NACL replaces the previous one.` }
                ]
            },
            {
                question: `For a DR plan with a 15-min RTO/RPO, which is the MOST cost-effective strategy for the application tier (EC2 instances in an ASG)?`,
                answers: [
                    { text: `Configure the DR Region with a full-scale ALB and Auto Scaling group.`, correct: false, explanation: `Running a full-scale copy (&apos;Hot Standby&apos;) would be very expensive and is more than what is required to meet a 15-minute RTO.` },
                    { text: `Configure the DR Region with a scaled-down ALB and Auto Scaling group (min/max/desired capacity of 1).`, correct: true, explanation: `Correct. This describes a &apos;Warm Standby&apos;. It&apos;s cost-effective, and during a failover, you can quickly scale up the Auto Scaling group to handle the full production load, meeting the RTO.` },
                    { text: `Manually launch a new ALB and Auto Scaling group during a failover.`, correct: false, explanation: `Manually launching the entire infrastructure from scratch during a disaster would take far too long and would not meet the 15-minute RTO.` },
                    { text: `Rely on Aurora Global Database for the application tier.`, correct: false, explanation: `Aurora Global Database provides the DR solution for the database tier, not the application tier (EC2 instances).` }
                ]
            },
            {
                question: `A VPC has a Site-to-Site VPN. New resources in a new AZ cannot communicate with the on-premises environment. What is the fix?`,
                answers: [
                    { text: `Add a route to the new subnets&apos; route tables that sends on-premises traffic to the virtual private gateway.`, correct: true, explanation: `Correct. For instances in new subnets to communicate with the on-premises network, their route table must have a rule that directs traffic for the on-premises network CIDR to the Virtual Private Gateway (VGW).` },
                    { text: `Create a ticket with AWS Support to add AZs to the VPN config.`, correct: false, explanation: `The VPN connection is to the VPC as a whole via the VGW; it is not tied to a specific AZ. This is a user configuration issue.` },
                    { text: `Establish a new Site-to-Site VPN connection for the new AZ.`, correct: false, explanation: `A single VPN connection to the VGW is sufficient for the entire VPC. You do not need separate VPN connections for each AZ.` },
                    { text: `Replace the Site-to-Site VPN with an AWS Direct Connect connection.`, correct: false, explanation: `While Direct Connect is another connectivity option, it is not necessary to solve this simple routing problem. The existing VPN is sufficient.` }
                ]
            },
            {
                question: `A company wants a solution that continuously monitors S3 bucket logging settings and automatically remediates any bucket that does not have logging enabled. What is the MOST efficient solution?`,
                answers: [
                    { text: `Track with CloudTrail and use a Lambda function for remediation.`, correct: false, explanation: `While possible, this is reinventing the wheel. AWS Config provides this functionality out of the box and is more efficient.` },
                    { text: `Configure automatic remediation in AWS Config by using the s3-bucket-logging-enabled rule.`, correct: true, explanation: `Correct. AWS Config is designed for this. It has a managed rule to check for logging and supports automatic remediation to fix non-compliant resources, making it the most efficient solution.` },
                    { text: `Use AWS Trusted Advisor to monitor and turn on logging.`, correct: false, explanation: `Trusted Advisor provides recommendations but does not offer automated remediation capabilities. It can identify the problem but cannot fix it.` },
                    { text: `Track with CloudWatch metrics and use a Lambda function for remediation.`, correct: false, explanation: `This is a custom solution that is less efficient than using the purpose-built AWS Config service for compliance and remediation.` }
                ]
            },
            {
                question: `An Auto Scaling group needs to always have 50% CPU available for bursts. Load increases significantly every day between 09:00 and 17:00. How should this be configured?`,
                answers: [
                    { text: `Create a target tracking policy for 90% CPU utilization.`, correct: false, explanation: `A target of 90% CPU utilization leaves only 10% headroom, violating the 50% availability requirement.` },
                    { text: `Create a target tracking policy for 50% CPU and scheduled scaling policies for 09:00 and 17:00.`, correct: true, explanation: `Correct. This combines reactive scaling (target tracking for 50% CPU to handle bursts) and proactive scaling (scheduled actions for predictable load changes), which is the most effective approach.` },
                    { text: `Set min/max/desired to 2 and use a scheduled policy.`, correct: false, explanation: `This configuration lacks a dynamic scaling policy (like target tracking) to handle unexpected bursts outside the scheduled window.` },
                    { text: `Create only scheduled scaling policies for 09:00 and 17:00.`, correct: false, explanation: `This option only includes proactive scaling and does not have a reactive policy to handle unpredictable traffic bursts.` }
                ]
            },
            {
                question: `A company wants to use CloudWatch to monitor instance-level metrics like memory utilization and available disk space on their EC2 instances. What must be done?`,
                answers: [
                    { text: `Configure CloudWatch from the console; AWS will automatically install agents.`, correct: false, explanation: `AWS does not automatically install the agent. This is a step the administrator must perform.` },
                    { text: `Install and configure the CloudWatch agent on all instances and attach an IAM role for permissions.`, correct: true, explanation: `Correct. To collect custom metrics from within the OS (like memory), you must install the CloudWatch agent. The agent needs permissions to send metrics, which is most securely provided by an IAM Role.` },
                    { text: `Install the CloudWatch agent and attach an IAM user for permissions.`, correct: false, explanation: `Using an IAM user&apos;s credentials on an instance is a security anti-pattern. IAM roles are the correct mechanism.` },
                    { text: `Install the CloudWatch agent and attach security groups for permissions.`, correct: false, explanation: `Security groups control network traffic, not permissions to call AWS APIs like CloudWatch. IAM roles are used for that purpose.` }
                ]
            },
            {
                question: `A company is migrating a production file server to AWS. Data must be accessible during an AZ failure, and users need SMB protocol and Windows ACLs. Which solution meets these requirements?`,
                answers: [
                    { text: `Create a single AWS Storage Gateway file gateway.`, correct: false, explanation: `A single file gateway would be a single point of failure and would not survive an AZ outage.` },
                    { text: `Create an Amazon FSx for Windows File Server Multi-AZ file system.`, correct: true, explanation: `Correct. This is the purpose-built service. It&apos;s a fully managed Windows file server supporting SMB and Windows ACLs, and the Multi-AZ option provides automatic failover for high availability.` },
                    { text: `Deploy two Storage Gateway file gateways behind an ALB.`, correct: false, explanation: `This is an overly complex and non-standard configuration for this use case.` },
                    { text: `Deploy two FSx Single-AZ 2 file systems and configure DFSR.`, correct: false, explanation: `This requires manual setup and management of DFSR. The Multi-AZ option in FSx provides the same high availability in a fully managed, more operationally efficient way.` }
                ]
            },
            {
                question: `An RDS DB instance is overutilized due to a high amount of read traffic. What is a primary method to improve performance?`,
                answers: [
                    { text: `Add a read replica.`, correct: true, explanation: `Correct. An RDS Read Replica is a read-only copy of your database. Directing read queries to the replica is a primary strategy for scaling the read capacity of a relational database and offloading the primary instance.` },
                    { text: `Migrate the database from RDS to Amazon DynamoDB.`, correct: false, explanation: `Migrating to DynamoDB (NoSQL) from a relational database is a massive architectural change, not a simple performance improvement.` },
                    { text: `Migrate the database to an EC2 instance with enhanced networking.`, correct: false, explanation: `Migrating to a self-managed database on EC2 increases operational overhead, and the bottleneck is described as reads, not network throughput.` },
                    { text: `Upgrade the database to a Multi-AZ deployment.`, correct: false, explanation: `Multi-AZ is a high-availability feature. It creates a standby replica for failover, but this standby is not accessible for read queries and does not improve read performance.` }
                ]
            },
            {
                question: `Flow logs for an EC2 instance behind an NLB show an ACCEPT for inbound traffic, followed by a REJECT for the return traffic. What is the reason?`,
                answers: [
                    { text: `The security group of the EC2 instances has no Allow rule for traffic from the NLB.`, correct: false, explanation: `If the security group blocked the inbound traffic, the first flow log entry would have been a REJECT, not an ACCEPT.` },
                    { text: `The security group of the NLB has no Allow rule for traffic from the on-premises environment.`, correct: false, explanation: `The flow log shows traffic did reach the EC2 instance, so the NLB successfully forwarded it. The problem is with the return path.` },
                    { text: `The ACL of the on-premises environment does not allow traffic to the AWS environment.`, correct: false, explanation: `The problem is with the return traffic from AWS to on-premises, not the initial traffic from on-premises to AWS.` },
                    { text: `The network ACL associated with the subnet does not allow outbound traffic for the ephemeral port range.`, correct: true, explanation: `Correct. Network ACLs are stateless. The REJECT record for the return traffic indicates the outbound NACL rule is blocking the response. The response must be allowed to the client&apos;s ephemeral port range (1024-65535).` }
                ]
            },
            {
                question: `An EC2 instance in a private subnet with an S3 gateway endpoint cannot upload a file to S3. What will solve this?`,
                answers: [
                    { text: `Update the EC2 instance role policy to include s3:PutObject access.`, correct: false, explanation: `Permissions are irrelevant if there is no network path for the EC2 instance to reach the S3 service. A connectivity failure must be solved first.` },
                    { text: `Update the EC2 security group to allow outbound traffic to 0.0.0.0/0 for port 80.`, correct: false, explanation: `The purpose of a gateway endpoint is to avoid sending traffic over the internet. This is unnecessary and would not use the private endpoint.` },
                    { text: `Update the EC2 subnet route table to include the S3 prefix list destination routes to the S3 gateway endpoint.`, correct: true, explanation: `Correct. A VPC gateway endpoint for S3 works by adding a specific route to the subnet&apos;s route table. If this route is missing, the EC2 instance has no path to reach S3.` },
                    { text: `Update the S3 bucket policy to allow s3:PutObject access from the private subnet.`, correct: false, explanation: `Like the IAM role, the bucket policy is irrelevant if there is no network connectivity between the instance and S3.` }
                ]
            },
            {
                question: `A company&apos;s CloudFormation templates repeatedly declare the same components (logging, security groups). How can these be made into reusable, parameterized templates?`,
                answers: [
                    { text: `Develop a CloudFormation change set.`, correct: false, explanation: `A change set is a preview of changes, not a mechanism for creating reusable components.` },
                    { text: `Develop CloudFormation macros.`, correct: false, explanation: `Macros are an advanced feature for custom processing on templates, more complex than what is needed for simple component reuse. Nested stacks are the standard approach.` },
                    { text: `Develop CloudFormation nested stacks.`, correct: true, explanation: `Correct. Nested stacks are designed for this. You create a standalone template for a common component and reference it from a parent template, allowing you to build complex stacks from reusable modules.` },
                    { text: `Develop CloudFormation stack sets.`, correct: false, explanation: `Stack sets are for deploying the same template across multiple accounts or regions, not for composing a single stack from reusable parts.` }
                ]
            },
            {
                question: `A serverless application uses multiple Lambda functions, each with its own log group. The security team needs a count of application errors, grouped by error type, from across all log groups. How can this be done?`,
                answers: [
                    { text: `Perform a CloudWatch Logs Insights query that uses the stats command and count function.`, correct: true, explanation: `Correct. CloudWatch Logs Insights is the purpose-built tool for this. It can query across multiple log groups and use powerful commands like &apos;stats count(*) by errorType&apos; for aggregation.` },
                    { text: `Perform a CloudWatch Logs search that uses the groupby keyword.`, correct: false, explanation: `The basic CloudWatch Logs search functionality does not support powerful aggregation and grouping keywords like &apos;groupby&apos;. That capability is part of Logs Insights.` },
                    { text: `Perform an Amazon Athena query on the logs.`, correct: false, explanation: `While you could export logs to S3 and query with Athena, this is much more complex and less immediate than using Logs Insights directly.` },
                    { text: `Perform an Amazon RDS query.`, correct: false, explanation: `RDS is a relational database service and has no direct way to query log data stored in CloudWatch Logs.` }
                ]
            },
            {
                question: `A SysOps administrator needs to define a custom health check for EC2 instances behind an Application Load Balancer. What is the MOST operationally efficient solution?`,
                answers: [
                    { text: `Have instances write status to a shared S3 bucket for the ALB to read.`, correct: false, explanation: `This is an overly complex and non-standard solution for a problem that has a simple, built-in feature.` },
                    { text: `Configure the health check on the ALB and ensure the Health Check Path setting is correct.`, correct: true, explanation: `Correct. ALBs have built-in health check functionality. You configure them on the target group, specifying a protocol, port, and a specific path (e.g., /health). This is the standard and most efficient method.` },
                    { text: `Use Amazon ElastiCache to track instance health.`, correct: false, explanation: `ElastiCache is an in-memory caching service and is not used for health checking of EC2 instances.` },
                    { text: `Configure an Amazon API Gateway health check.`, correct: false, explanation: `This is an overly complex, non-standard solution. The ALB is designed to perform these health checks directly.` }
                ]
            },
            {
                question: `An errant process on an EC2 instance occasionally runs at 100% CPU. A SysOps administrator wants to automatically restart the instance if this persists for more than 2 minutes. How can this be accomplished?`,
                answers: [
                    { text: `Create a CloudWatch alarm with basic monitoring and a restart action.`, correct: false, explanation: `Basic monitoring provides data every 5 minutes, which is not granular enough to detect a condition that persists for only 2 minutes.` },
                    { text: `Create a CloudWatch alarm with detailed monitoring and a restart action.`, correct: true, explanation: `Correct. Detailed monitoring provides metrics at a 1-minute frequency. An alarm can be set to trigger if CPUUtilization is >= 100% for 2 consecutive periods (2 minutes) and can be configured with a built-in EC2 action to reboot the instance.` },
                    { text: `Create a Lambda function to restart the instance, invoked every 2 minutes.`, correct: false, explanation: `This is inefficient and not event-driven. A CloudWatch alarm is the proper event-driven mechanism for this.` },
                    { text: `Create a Lambda function invoked by EC2 health checks.`, correct: false, explanation: `EC2 health checks monitor the underlying host and instance reachability, not in-guest metrics like CPU utilization.` }
                ]
            },
            {
                question: `A company is migrating several high-performance computing (HPC) virtual machines to EC2. The deployment must minimize network latency and maximize throughput between the instances. Which strategy should be chosen?`,
                answers: [
                    { text: `Deploy the instances in a cluster placement group in one Availability Zone.`, correct: true, explanation: `Correct. A Cluster Placement Group is designed for this use case. It packs instances close together on the same underlying hardware within a single AZ to provide the lowest latency and highest throughput between them.` },
                    { text: `Deploy the instances in a partition placement group in two Availability Zones.`, correct: false, explanation: `A Partition Placement Group spreads instances across logical partitions to reduce the impact of correlated hardware failures. It does not prioritize low-latency communication.` },
                    { text: `Deploy the instances in a partition placement group in one Availability Zone.`, correct: false, explanation: `A Partition Placement Group&apos;s primary purpose is high availability, not the lowest possible latency between instances.` },
                    { text: `Deploy the instances in a spread placement group in two Availability Zones.`, correct: false, explanation: `A Spread Placement Group places each instance on distinct hardware to maximize availability, which results in higher latency between them compared to a cluster group.` }
                ]
            }
        ];

        // DOM Elements
        const questionText = document.getElementById('question-text');
        const answerButtons = document.getElementById('answer-buttons');
        const nextBtn = document.getElementById('next-btn');
        const restartBtn = document.getElementById('restart-btn');
        const questionCounter = document.getElementById('question-counter');
        const scoreDisplay = document.getElementById('score');
        const resultsArea = document.getElementById('results-area');
        const finalScoreText = document.getElementById('final-score');
        const quizHeader = document.getElementById('quiz-header');
        const questionArea = document.getElementById('question-area');
        const feedbackArea = document.getElementById('feedback-area');
        const explanationText = document.getElementById('explanation-text');

        // Quiz State
        let currentQuestionIndex = 0;
        let score = 0;

        function startQuiz() {
            // Add an 'answered' flag to each question for scoring first attempts
            questions.forEach(q => q.answered = false);
            currentQuestionIndex = 0;
            score = 0;
            resultsArea.classList.add('hidden');
            quizHeader.classList.remove('hidden');
            questionArea.classList.remove('hidden');
            feedbackArea.classList.add('hidden');
            nextBtn.classList.add('hidden');
            updateProgress();
            showQuestion();
        }

        function updateProgress() {
            questionCounter.textContent = `Question ${currentQuestionIndex + 1} of ${questions.length}`;
            scoreDisplay.textContent = `Score: ${score}`;
        }

        function showQuestion() {
            resetState();
            const currentQuestion = questions[currentQuestionIndex];
            questionText.innerHTML = currentQuestion.question;
            currentQuestion.answers.forEach((answer, index) => {
                const button = document.createElement('button');
                button.innerHTML = answer.text;
                button.classList.add('answer-btn', 'w-full', 'text-left', 'p-4', 'rounded-lg', 'border-2', 'border-gray-300', 'bg-white', 'text-gray-700', 'hover:bg-gray-50');
                button.dataset.index = index; // Use index to find the answer object later
                button.addEventListener('click', selectAnswer);
                answerButtons.appendChild(button);
            });
        }

        function resetState() {
            nextBtn.classList.add('hidden');
            feedbackArea.classList.add('hidden');
            while (answerButtons.firstChild) {
                answerButtons.removeChild(answerButtons.firstChild);
            }
        }

        function selectAnswer(e) {
            const selectedBtn = e.target.closest('button');
            const answerIndex = parseInt(selectedBtn.dataset.index);
            const currentQuestion = questions[currentQuestionIndex];
            const selectedAnswer = currentQuestion.answers[answerIndex];
            const isCorrect = selectedAnswer.correct;
            const isFirstAttempt = !currentQuestion.answered;

            // Only score the first correct attempt
            if (isCorrect && isFirstAttempt) {
                score++;
            }
            
            // Mark question as answered and show Next button on first attempt
            if (isFirstAttempt) {
                currentQuestion.answered = true;
                nextBtn.classList.remove('hidden');
            }

            // Reset styles on all buttons before applying new ones
            Array.from(answerButtons.children).forEach(button => {
                button.classList.remove('correct', 'incorrect');
            });
            
            // Apply style to the selected button if it's incorrect
            if (!isCorrect) {
                selectedBtn.classList.add('incorrect');
            }

            // Always highlight the correct answer
            Array.from(answerButtons.children).forEach((button, index) => {
                if (currentQuestion.answers[index].correct) {
                    button.classList.add('correct');
                }
            });
            
            // Show explanation for the selected answer
            explanationText.innerHTML = selectedAnswer.explanation;
            feedbackArea.classList.remove('hidden');
            updateProgress();
        }

        function showResults() {
            quizHeader.classList.add('hidden');
            questionArea.classList.add('hidden');
            feedbackArea.classList.add('hidden');
            nextBtn.classList.add('hidden');
            resultsArea.classList.remove('hidden');
            const percentage = Math.round((score / questions.length) * 100);
            finalScoreText.innerHTML = `You scored <span class="font-bold text-blue-600">${score}</span> out of <span class="font-bold text-blue-600">${questions.length}</span> (${percentage}%)`;
        }
        
        nextBtn.addEventListener('click', () => {
            currentQuestionIndex++;
            if (currentQuestionIndex < questions.length) {
                updateProgress();
                showQuestion();
            } else {
                showResults();
            }
        });

        restartBtn.addEventListener('click', startQuiz);
        
        // Initial start
        startQuiz();
    </script>
</body>
</html>
